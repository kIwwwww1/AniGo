# Конфигурация VPS сервера для 50 пользователей

## Анализ проекта

### Архитектура приложения

Ваше приложение AniGo (Yumivo) состоит из:

1. **Backend** (FastAPI/Python)
   - FastAPI с Uvicorn
   - Асинхронные запросы к БД
   - Пул соединений: 20 базовых + 40 дополнительных (до 60)

2. **Frontend** (React/Vite)
   - Статические файлы после сборки
   - Обслуживается через Nginx

3. **База данных** (PostgreSQL 15)
   - Хранит: пользователи, аниме, эпизоды, избранное, рейтинги, комментарии, история просмотров
   - Множество связанных таблиц

4. **Кэш** (Redis) - опционально, но рекомендуется
   - Кэширование профилей пользователей
   - Кэширование популярных аниме
   - Лимит памяти: 256MB

5. **Reverse Proxy** (Nginx)
   - SSL/TLS терминация
   - Статические файлы frontend
   - Rate limiting

6. **Хранилище медиа** (S3 - Selectel)
   - Аватары пользователей
   - Изображения (внешнее хранилище, не требует ресурсов VPS)

### Оценка нагрузки на 50 пользователей

**Активность пользователей:**
- Одновременно онлайн: ~10-15 пользователей (20-30% от общего числа)
- Пиковая нагрузка: ~20-25 пользователей одновременно
- Средняя активность: 5-8 запросов в минуту на пользователя

**Объем данных (примерная оценка):**
- Пользователи: 50 записей × ~2KB = ~100KB
- Аниме каталог: зависит от количества, но обычно ~1000-5000 записей × ~5KB = ~5-25MB
- История просмотров: 50 пользователей × ~100 записей × ~100 bytes = ~500KB
- Избранное: 50 пользователей × ~50 записей × ~100 bytes = ~250KB
- Комментарии: ~1000-5000 записей × ~500 bytes = ~500KB-2.5MB
- Рейтинги: 50 пользователей × ~50 записей × ~100 bytes = ~250KB

**Итого база данных:** ~10-30MB данных + индексы (~5-10MB) = **15-40MB**

## Рекомендуемая конфигурация VPS

### Минимальная конфигурация (экономичный вариант)

```
CPU: 2 ядра
RAM: 4 GB
Диск: 40 GB SSD
Пропускная способность: 100 Мбит/с
```

**Распределение памяти:**
- PostgreSQL: ~1.5GB (shared_buffers=512MB, effective_cache_size=3GB)
- Redis: ~256MB
- Backend (Python/FastAPI): ~512MB-1GB
- Frontend (Nginx): ~128MB
- Система (OS, Docker): ~1GB
- Запас: ~1GB

**Оценка стоимости:** ~$10-15/месяц (Hetzner, DigitalOcean, Yandex Cloud)

### Рекомендуемая конфигурация (оптимальная)

```
CPU: 4 ядра
RAM: 8 GB
Диск: 60 GB SSD
Пропускная способность: 100-200 Мбит/с
```

**Распределение памяти:**
- PostgreSQL: ~2.5GB (shared_buffers=1GB, effective_cache_size=4GB)
- Redis: ~512MB
- Backend (Python/FastAPI): ~1-1.5GB (можно запустить 2-4 workers)
- Frontend (Nginx): ~256MB
- Система (OS, Docker): ~1.5GB
- Запас: ~2GB (для пиковых нагрузок)

**Преимущества:**
- Больше ресурсов для обработки запросов
- Возможность масштабирования backend workers
- Комфортная работа при пиковых нагрузках
- Запас для роста пользовательской базы

**Оценка стоимости:** ~$20-30/месяц

### Рекомендация

**Для 50 пользователей рекомендуется: 4 CPU / 8 GB RAM / 60 GB SSD**

Это обеспечит:
- ✅ Комфортную работу без замедлений
- ✅ Запас для роста до 100-150 пользователей
- ✅ Возможность оптимизации (workers, кэширование)
- ✅ Стабильную работу всех сервисов

## Настройки PostgreSQL для 8GB RAM

Обновите настройки PostgreSQL в `docker-compose.prod.yml`:

```yaml
db:
  command: >
    postgres
    -c max_connections=100
    -c shared_buffers=1GB
    -c effective_cache_size=4GB
    -c maintenance_work_mem=256MB
    -c checkpoint_completion_target=0.9
    -c wal_buffers=16MB
    -c default_statistics_target=100
    -c random_page_cost=1.1
    -c effective_io_concurrency=200
    -c work_mem=4MB
    -c min_wal_size=512MB
    -c max_wal_size=2GB
```

**Изменения от текущих настроек:**
- `max_connections`: 200 → 100 (достаточно для 50 пользователей)
- `shared_buffers`: 2GB → 1GB (оптимально для 8GB RAM)
- `effective_cache_size`: 6GB → 4GB (соответствует доступной памяти)
- `maintenance_work_mem`: 512MB → 256MB
- `work_mem`: 10MB → 4MB (для уменьшения потребления памяти)
- `min_wal_size`: 1GB → 512MB
- `max_wal_size`: 4GB → 2GB

## Настройки Backend для 50 пользователей

### Добавьте Redis в docker-compose.prod.yml

Рекомендуется добавить Redis для кэширования:

```yaml
redis:
  image: redis:7-alpine
  container_name: anigo-redis-prod
  restart: unless-stopped
  volumes:
    - redis_data:/data
  command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
  networks:
    - anigo-network
  healthcheck:
    test: ["CMD", "redis-cli", "ping"]
    interval: 10s
    timeout: 3s
    retries: 3
```

И добавьте в volumes:
```yaml
volumes:
  redis_data:
    driver: local
```

### Backend workers

Для 50 пользователей достаточно 2-4 workers:

```yaml
backend:
  command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2
```

Или с uvloop для лучшей производительности:
```yaml
backend:
  command: uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 2 --loop uvloop
```

Добавьте в `backend/requirements.txt`:
```
uvloop
```

## Требования к диску

### Текущий объем данных
- База данных: ~15-40MB (для 50 пользователей)
- Docker образы: ~2-3GB
- Логи: ~100-500MB/месяц
- Резервные копии БД: ~50-100MB

### Рекомендации по диску

**Минимум: 40GB SSD**
- База данных: ~100MB-1GB (с учетом роста)
- Docker: ~5GB
- Логи: ~2GB (6 месяцев хранения)
- Резервные копии: ~5GB
- Система: ~10GB
- Запас: ~20GB (для роста)

**Рекомендуется: 60GB SSD** для комфортной работы

### Резервное копирование

Настройте автоматические бэкапы базы данных:

```bash
# Создайте скрипт для бэкапа
#!/bin/bash
# backup.sh
docker exec anigo-db-prod pg_dump -U ${POSTGRES_USER} ${POSTGRES_DB} > backup_$(date +%Y%m%d_%H%M%S).sql

# Добавьте в crontab (ежедневно в 3:00)
0 3 * * * /path/to/backup.sh
```

## Сетевые требования

### Пропускная способность

**Для 50 пользователей:**
- Средняя нагрузка: ~5-10 Мбит/с
- Пиковая нагрузка: ~20-30 Мбит/с
- Рекомендуется: **100 Мбит/с**

### Трафик в месяц

- Статические файлы (frontend, изображения из S3): ~10-20GB
- API запросы: ~5-10GB
- **Итого: ~20-30GB/месяц**

Для большинства провайдеров это входит в базовый тариф.

## Мониторинг ресурсов

### Команды для проверки использования

```bash
# Использование памяти
free -h

# Использование CPU
top
# или
htop

# Использование диска
df -h

# Использование ресурсов Docker контейнерами
docker stats

# Логи PostgreSQL
docker-compose -f docker-compose.prod.yml logs db

# Проверка подключений к БД
docker exec anigo-db-prod psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} -c "SELECT count(*) FROM pg_stat_activity;"
```

## Рекомендации по оптимизации

1. **Включите Redis кэширование**
   - Уменьшит нагрузку на PostgreSQL
   - Ускорит ответы API

2. **Настройте Nginx кэширование**
   - Кэшируйте статические файлы
   - Установите правильные заголовки Cache-Control

3. **Используйте gzip сжатие в Nginx**
   - Уменьшит трафик
   - Ускорит загрузку страниц

4. **Мониторинг**
   - Настройте логирование
   - Используйте простой мониторинг (например, Netdata)

5. **Оптимизация базы данных**
   - Регулярно выполняйте VACUUM
   - Следите за размером индексов

## Масштабирование

При росте до 100-200 пользователей:

1. **Увеличьте RAM до 16GB**
2. **Добавьте больше backend workers** (4-6)
3. **Увеличьте shared_buffers PostgreSQL** до 2GB
4. **Рассмотрите использование connection pooling** (PgBouncer)

## Альтернативная конфигурация: 3 CPU / 5 GB RAM / 30 GB SSD

### Оценка пригодности

**Конфигурация:** 3 CPU / 5 GB RAM / 30 GB SSD

#### ✅ CPU: 3 ядра - ПОДХОДИТ

- Достаточно для 50 пользователей
- Можно запустить 2 backend workers
- Умеренная нагрузка на процессор

#### ⚠️ RAM: 5 GB - РАБОТАЕТ, НО ТЕСНО

**Распределение памяти для 5GB:**
- PostgreSQL: ~1.5GB (shared_buffers=512MB, effective_cache_size=2GB)
- Redis: ~256MB (можно уменьшить до 128MB при необходимости)
- Backend (Python/FastAPI): ~512-768MB (2 workers)
- Frontend (Nginx): ~128MB
- Система (OS, Docker): ~1GB
- Запас: ~0.5-1GB (минимум)

**Проблемы:**
- ❌ Мало запаса для пиковых нагрузок
- ❌ При росте пользователей будет нехватка памяти
- ⚠️ Нужна тщательная оптимизация настроек

**Настройки PostgreSQL для 5GB RAM:**
```yaml
db:
  command: >
    postgres
    -c max_connections=80
    -c shared_buffers=512MB
    -c effective_cache_size=2GB
    -c maintenance_work_mem=128MB
    -c checkpoint_completion_target=0.9
    -c wal_buffers=16MB
    -c default_statistics_target=100
    -c random_page_cost=1.1
    -c effective_io_concurrency=200
    -c work_mem=3MB
    -c min_wal_size=256MB
    -c max_wal_size=1GB
```

#### ❌ Диск: 30 GB - КРИТИЧЕСКИ МАЛО

**Распределение дискового пространства:**
- База данных: ~100MB-1GB
- Docker образы: ~5GB
- Логи (6 месяцев): ~2GB
- Резервные копии БД: ~3-5GB
- Система (OS): ~8-10GB
- Запас: ~7-9GB (в идеале)

**Проблемы:**
- ❌ Очень тесно для комфортной работы
- ❌ Недостаточно места для логов и бэкапов
- ❌ Риск заполнения диска
- ⚠️ Потребуется регулярная очистка старых логов и бэкапов

**Рекомендации по экономии места:**
1. Настройте ротацию логов (храните не более 1-2 месяцев)
2. Храните бэкапы на внешнем хранилище (S3)
3. Очищайте неиспользуемые Docker образы: `docker system prune -a`
4. Используйте сжатие бэкапов

### Вывод по конфигурации 3/5/30

**Для старта с 50 пользователями: ⚠️ РАБОТАЕТ, НО НЕ РЕКОМЕНДУЕТСЯ**

**Плюсы:**
- ✅ Можно начать работу
- ✅ Экономия средств
- ✅ CPU достаточно

**Минусы:**
- ❌ Мало оперативной памяти (риск проблем при нагрузке)
- ❌ Критически мало диска (риск заполнения)
- ❌ Нет запаса для роста
- ❌ Потребуется постоянный мониторинг ресурсов

**Рекомендации:**
1. **Минимальная альтернатива:** Если бюджет ограничен, лучше взять **4 GB RAM / 40 GB SSD** (даже если меньше CPU)
2. **Оптимальный вариант:** Увеличьте до **5-6 GB RAM / 40-50 GB SSD**
3. Если используете эту конфигурацию:
   - Обязательно настройте мониторинг диска
   - Настройте автоматическую очистку логов
   - Храните бэкапы на S3
   - Планируйте апгрейд в ближайшее время

## Итоговая рекомендация

**Для 50 пользователей:**
- ✅ **4 CPU / 8 GB RAM / 60 GB SSD** (оптимально)
- ⚠️ **3 CPU / 5 GB RAM / 40 GB SSD** (минимум для комфорта)
- ❌ **3 CPU / 5 GB RAM / 30 GB SSD** (только для старта с ограничениями)
- ✅ **100 Мбит/с пропускная способность**
- ✅ **Стоимость оптимальной: ~$20-30/месяц**
- ✅ **Стоимость минимальной: ~$15-20/месяц**

**Провайдеры VPS:**
- Hetzner (Немецкий, хорошее соотношение цена/качество)
- DigitalOcean (Международный, простая настройка)
- Yandex Cloud (Российский, быстрая поддержка)
- Timeweb (Российский, доступные цены)
- Selectel (Российский, если используете их S3)
