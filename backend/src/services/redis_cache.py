"""
–£—Ç–∏–ª–∏—Ç—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Redis –∫—ç—à–µ–º
"""
from loguru import logger
import redis.asyncio as redis
import os
import json
import functools
import hashlib
from typing import Any, Callable
from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import AsyncSession

load_dotenv()

_redis_client: redis.Redis | None = None

async def get_redis_client() -> redis.Redis | None:
    """–ü–æ–ª—É—á–∏—Ç—å –∫–ª–∏–µ–Ω—Ç Redis"""
    global _redis_client
    
    if _redis_client is not None:
        return _redis_client
    
    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º REDIS_URL
    redis_url = os.getenv("REDIS_URL")
    
    # –ï—Å–ª–∏ REDIS_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, —Å–æ–±–∏—Ä–∞–µ–º URL –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    if not redis_url:
        redis_host = os.getenv("REDIS_HOST", "localhost")
        redis_port = os.getenv("REDIS_PORT", "6379")
        redis_db = os.getenv("REDIS_DB", "0")
        redis_password = os.getenv("REDIS_PASSWORD", "")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º URL –¥–ª—è Redis
        if redis_password:
            redis_url = f"redis://:{redis_password}@{redis_host}:{redis_port}/{redis_db}"
        else:
            redis_url = f"redis://{redis_host}:{redis_port}/{redis_db}"
        
        logger.debug(f"–°–æ–±—Ä–∞–Ω Redis URL –∏–∑ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö: redis://{redis_host}:{redis_port}/{redis_db}")
    
    if not redis_url:
        logger.warning("REDIS_URL –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –∏ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ Redis –Ω–µ –Ω–∞–π–¥–µ–Ω—ã, Redis –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–∫–ª—é—á–µ–Ω–æ")
        return None
    
    try:
        _redis_client = redis.from_url(redis_url, decode_responses=True)
        await _redis_client.ping()
        logger.info("‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ Redis —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        return _redis_client
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ Redis: {e}")
        return None


async def close_redis_client():
    """–ó–∞–∫—Ä—ã—Ç—å —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis"""
    global _redis_client
    if _redis_client:
        await _redis_client.close()
        _redis_client = None
        logger.info("‚úÖ –°–æ–µ–¥–∏–Ω–µ–Ω–∏–µ —Å Redis –∑–∞–∫—Ä—ã—Ç–æ")


async def clear_cache_pattern(pattern: str):
    """–û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É"""
    redis = await get_redis_client()
    if redis:
        try:
            keys = []
            async for key in redis.scan_iter(match=pattern):
                keys.append(key)
            
            if keys:
                await redis.delete(*keys)
                logger.info(f"Cleared {len(keys)} cache keys matching: {pattern}")
        except Exception as e:
            logger.error(f"Failed to clear cache pattern {pattern}: {e}")


async def clear_all_cache():
    """–û—á–∏—Å—Ç–∏—Ç—å –≤–µ—Å—å –∫—ç—à"""
    redis = await get_redis_client()
    if redis:
        try:
            await redis.flushdb()
            logger.info("‚úÖ All cache cleared")
        except Exception as e:
            logger.error(f"Failed to clear all cache: {e}")


async def get_cache_info() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –∫—ç—à–µ"""
    redis = await get_redis_client()
    if redis:
        try:
            info = await redis.info()
            db_size = await redis.dbsize()
            return {
                "connected": True,
                "db_size": db_size,
                "memory_used": info.get("used_memory_human", "N/A"),
                "keyspace_hits": info.get("keyspace_hits", 0),
                "keyspace_misses": info.get("keyspace_misses", 0),
            }
        except Exception as e:
            logger.error(f"Failed to get cache info: {e}")
            return {"connected": False, "error": str(e)}

    return {"connected": False, "error": "Redis client not initialized"}


async def clear_user_profile_cache(username: str, user_id: int = None):
    """
    –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    Args:
        username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        user_id: ID –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –¥–ª—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–∏)
    
    Returns:
        int: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–¥–∞–ª–µ–Ω–Ω—ã—Ö –∫–ª—é—á–µ–π –∫—ç—à–∞
    """
    redis = await get_redis_client()
    if not redis:
        logger.debug(f"Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ—á–∏—Å—Ç–∫—É –∫—ç—à–∞ –¥–ª—è {username}")
        return 0
    
    try:
        total_deleted = 0
        
        # –û—á–∏—â–∞–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫—ç—à –ø—Ä–æ—Ñ–∏–ª—è –ø–æ username (—Ç–æ—á–Ω—ã–π –∫–ª—é—á)
        cache_key = get_user_profile_cache_key(username)
        deleted = await redis.delete(cache_key)
        if deleted:
            total_deleted += deleted
            logger.debug(f"üóëÔ∏è Cleared profile cache for user: {username} (key: {cache_key})")
        
        # –¢–∞–∫–∂–µ –æ—á–∏—â–∞–µ–º –∫—ç—à –ø–æ –ø–∞—Ç—Ç–µ—Ä–Ω—É (–Ω–∞ —Å–ª—É—á–∞–π –¥—Ä—É–≥–∏—Ö –∫–ª—é—á–µ–π)
        pattern_username = f"user_profile:*{username}*"
        keys_username = []
        async for key in redis.scan_iter(match=pattern_username):
            if key != cache_key:  # –£–∂–µ —É–¥–∞–ª–∏–ª–∏ –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª—é—á
                keys_username.append(key)
        
        if keys_username:
            deleted_count = await redis.delete(*keys_username)
            total_deleted += deleted_count
            logger.debug(f"üóëÔ∏è Cleared {deleted_count} additional cache keys for user: {username}")
        
        # –¢–∞–∫–∂–µ –æ—á–∏—â–∞–µ–º –∫—ç—à –Ω–∞—Å—Ç—Ä–æ–µ–∫ –ø—Ä–æ—Ñ–∏–ª—è
        settings_pattern = f"user_profile_settings:*{username}*"
        keys_settings = []
        async for key in redis.scan_iter(match=settings_pattern):
            keys_settings.append(key)
        
        if keys_settings:
            deleted_count = await redis.delete(*keys_settings)
            total_deleted += deleted_count
            logger.debug(f"üóëÔ∏è Cleared {deleted_count} settings cache keys for user: {username}")
        
        if total_deleted > 0:
            logger.info(f"‚úÖ Cleared {total_deleted} cache keys for user: {username}")
        else:
            logger.debug(f"‚ÑπÔ∏è No cache keys found to clear for user: {username}")
        
        return total_deleted
                
    except Exception as e:
        logger.error(f"‚ùå Failed to clear user profile cache for {username}: {e}")
        return 0


def get_user_profile_cache_key(username: str) -> str:
    """
    –ü–æ–ª—É—á–∏—Ç—å –∫–ª—é—á –∫—ç—à–∞ –¥–ª—è –ø—Ä–æ—Ñ–∏–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    Args:
        username: –ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    
    Returns:
        –ö–ª—é—á –∫—ç—à–∞
    """
    return f"user_profile:{username}"


async def clear_most_favorited_cache():
    """
    –û—á–∏—Å—Ç–∏—Ç—å –∫—ç—à —Ç–æ–ø –∫–æ–ª–ª–µ–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ (most favorited users)
    """
    redis = await get_redis_client()
    if redis:
        try:
            pattern = "most_favorited_users:*"
            keys = []
            async for key in redis.scan_iter(match=pattern):
                keys.append(key)
            
            if keys:
                await redis.delete(*keys)
                logger.info(f"üóëÔ∏è –û—á–∏—â–µ–Ω –∫—ç—à Redis –¥–ª—è —Ç–æ–ø –∫–æ–ª–ª–µ–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤: {len(keys)} –∫–ª—é—á–µ–π")
            else:
                logger.debug("–ö—ç—à –¥–ª—è —Ç–æ–ø –∫–æ–ª–ª–µ–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –∫—ç—à–∞ —Ç–æ–ø –∫–æ–ª–ª–µ–∫—Ü–∏–æ–Ω–µ—Ä–æ–≤: {e}")


def serialize_sqlalchemy_obj(obj):
    """
    –°–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–±—ä–µ–∫—Ç SQLAlchemy –≤ —Å–ª–æ–≤–∞—Ä—å
    
    Args:
        obj: –û–±—ä–µ–∫—Ç SQLAlchemy –º–æ–¥–µ–ª–∏
    
    Returns:
        dict: –°–ª–æ–≤–∞—Ä—å —Å –¥–∞–Ω–Ω—ã–º–∏ –æ–±—ä–µ–∫—Ç–∞
    """
    if obj is None:
        return None
    elif isinstance(obj, dict):
        return obj
    elif isinstance(obj, (list, tuple)):
        return [serialize_sqlalchemy_obj(item) for item in obj]
    elif hasattr(obj, '__table__'):
        # –≠—Ç–æ –æ–±—ä–µ–∫—Ç SQLAlchemy –º–æ–¥–µ–ª–∏
        result = {}
        try:
            for column in obj.__table__.columns:
                value = getattr(obj, column.name, None)
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º datetime –∏ –¥—Ä—É–≥–∏–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–µ —Ç–∏–ø—ã
                if hasattr(value, 'isoformat'):
                    result[column.name] = value.isoformat()
                elif isinstance(value, (int, float, str, bool)):
                    result[column.name] = value
                elif value is None:
                    result[column.name] = None
                else:
                    # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
                    result[column.name] = str(value)
            return result
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –æ–±—ä–µ–∫—Ç–∞ SQLAlchemy: {e}")
            return None
    elif isinstance(obj, (int, float, str, bool)):
        return obj
    else:
        # –î–ª—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã—Ö —Ç–∏–ø–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
        logger.debug(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ç–∏–ø –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏: {type(obj)}, –∑–Ω–∞—á–µ–Ω–∏–µ: {str(obj)[:100]}")
        return str(obj)


def serialize_for_cache(data):
    """
    –°–µ—Ä–∏–∞–ª–∏–∑–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫—ç—à–∞ (–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å SQLAlchemy –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏)
    
    Args:
        data: –î–∞–Ω–Ω—ã–µ –¥–ª—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ (–º–æ–∂–µ—Ç –±—ã—Ç—å —Å–ø–∏—Å–∫–æ–º, –æ–±—ä–µ–∫—Ç–æ–º SQLAlchemy –∏ —Ç.–¥.)
    
    Returns:
        –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã–µ –¥–∞–Ω–Ω—ã–µ (—Å–ª–æ–≤–∞—Ä–∏, —Å–ø–∏—Å–∫–∏, –ø—Ä–∏–º–∏—Ç–∏–≤—ã)
    """
    if isinstance(data, list):
        return [serialize_sqlalchemy_obj(item) for item in data]
    else:
        return serialize_sqlalchemy_obj(data)


def redis_cached(prefix: str, ttl: int = 300):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ async —Ñ—É–Ω–∫—Ü–∏–π –≤ Redis
    
    Args:
        prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∫–ª—é—á–∞ –∫—ç—à–∞
        ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 300 —Å–µ–∫—É–Ω–¥ = 5 –º–∏–Ω—É—Ç)
    
    Usage:
        @redis_cached(prefix="popular", ttl=300)
        async def get_popular_anime(...):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç Redis
            redis_client = await get_redis_client()
            
            # –ï—Å–ª–∏ Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
            if not redis_client:
                return await func(*args, **kwargs)
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
            # –î–ª—è —Å–µ—Å—Å–∏–π –∏ –¥—Ä—É–≥–∏—Ö –Ω–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö id –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            cache_key_parts = [prefix]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –∫–ª—é—á –∫—ç—à–∞
            for arg in args:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º AsyncSession - —Å–µ—Å—Å–∏—è –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—ç—à–∏—Ä—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
                if isinstance(arg, AsyncSession):
                    continue
                elif hasattr(arg, 'id'):
                    cache_key_parts.append(str(arg.id))
                elif isinstance(arg, (int, str, float, bool)):
                    cache_key_parts.append(str(arg))
                elif hasattr(arg, '__dict__'):
                    # –î–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ —Å–æ–∑–¥–∞–µ–º —Ö—ç—à
                    arg_str = json.dumps(vars(arg), default=str, sort_keys=True)
                    arg_hash = hashlib.md5(arg_str.encode()).hexdigest()[:8]
                    cache_key_parts.append(arg_hash)
            
            # –î–æ–±–∞–≤–ª—è–µ–º kwargs (–∏—Å–∫–ª—é—á–∞—è —Å–µ—Å—Å–∏–∏)
            if kwargs:
                # –§–∏–ª—å—Ç—Ä—É–µ–º kwargs, –∏—Å–∫–ª—é—á–∞—è AsyncSession
                filtered_kwargs = {
                    k: v for k, v in kwargs.items() 
                    if not isinstance(v, AsyncSession)
                }
                if filtered_kwargs:
                    kwargs_str = json.dumps(filtered_kwargs, default=str, sort_keys=True)
                    kwargs_hash = hashlib.md5(kwargs_str.encode()).hexdigest()[:8]
                    cache_key_parts.append(kwargs_hash)
            
            cache_key = ":".join(cache_key_parts)
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞
                cached_data = await redis_client.get(cache_key)
                if cached_data is not None:
                    try:
                        deserialized = json.loads(cached_data)
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã (–Ω–µ —Å—Ç—Ä–æ–∫–∏ —Å –æ–±—ä–µ–∫—Ç–∞–º–∏)
                        is_valid = True
                        if isinstance(deserialized, list):
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞
                            for item in deserialized:
                                if isinstance(item, str) and ('object at 0x' in item or 'AnimeModel' in item or 'Model' in item):
                                    is_valid = False
                                    break
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç) –∏–ª–∏ –æ–±—ä–µ–∫—Ç SQLAlchemy
                                if not isinstance(item, dict) and not hasattr(item, '__table__'):
                                    if isinstance(item, str):
                                        is_valid = False
                                        break
                        elif isinstance(deserialized, str):
                            # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å –æ–±—ä–µ–∫—Ç–æ–º - –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
                            if 'object at 0x' in deserialized or 'AnimeModel' in deserialized:
                                is_valid = False
                        
                        if not is_valid:
                            logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç), –æ—á–∏—â–∞–µ–º –∫–ª—é—á: {cache_key}")
                            await redis_client.delete(cache_key)
                            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º)
                        else:
                            # –ü–æ–ª—É—á–∞–µ–º TTL –∫–ª—é—á–∞ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                            remaining_ttl = await redis_client.ttl(cache_key)
                            logger.debug(f"üéØ Cache HIT: {func.__name__} (key: {cache_key}, TTL remaining: {remaining_ttl}s)")
                            return deserialized
                    except json.JSONDecodeError as e:
                        logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫—ç—à–∞ –¥–ª—è {func.__name__}: {e}, –æ—á–∏—â–∞–µ–º –∫–ª—é—á: {cache_key}")
                        await redis_client.delete(cache_key)
                
                # –ö—ç—à –ø—Ä–æ–º–∞—Ö - –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
                logger.info(f"üí® Cache MISS: {func.__name__} (key: {cache_key}) - –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å –∫ –ë–î")
                result = await func(*args, **kwargs)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫—ç—à
                try:
                    # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º SQLAlchemy –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                    serializable_result = serialize_for_cache(result)
                    serialized_result = json.dumps(serializable_result, default=str)
                    result_size = len(serialized_result.encode('utf-8'))
                    await redis_client.setex(cache_key, ttl, serialized_result)
                    logger.info(f"üíæ Cached {func.__name__} (TTL: {ttl}s, key: {cache_key}, size: {result_size} bytes)")
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to cache result for {func.__name__}: {e}")
                
                return result
                
            except Exception as e:
                logger.error(f"Redis cache error for {func.__name__}: {e}")
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –±–µ–∑ –∫—ç—à–∞
                return await func(*args, **kwargs)
        
        return wrapper
    return decorator


def redis_cached_limited(prefix: str, ttl: int = 300, max_cache_items: int = 18):
    """
    –î–µ–∫–æ—Ä–∞—Ç–æ—Ä –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ async —Ñ—É–Ω–∫—Ü–∏–π –≤ Redis —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    
    –ö—ç—à–∏—Ä—É–µ—Ç —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ max_cache_items —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–∑ —Å–ø–∏—Å–∫–∞ –ø—Ä–∏ offset=0.
    –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –ø–∞–≥–∏–Ω–∞—Ü–∏–∏, —á—Ç–æ–±—ã –Ω–µ —Ö—Ä–∞–Ω–∏—Ç—å –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ.
    
    –ü—Ä–∞–≤–∏–ª–∞ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è:
    - –ö—ç—à–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –¥–ª—è offset=0
    - –í –∫—ç—à —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ max_cache_items —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    - –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å offset=0 –∏ limit <= max_cache_items, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫—ç—à
    - –ü—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ —Å offset > 0 –∏–ª–∏ limit > max_cache_items, –∫—ç—à –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è
    
    Args:
        prefix: –ü—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –∫–ª—é—á–∞ –∫—ç—à–∞
        ttl: –í—Ä–µ–º—è –∂–∏–∑–Ω–∏ –∫—ç—à–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 300 —Å–µ–∫—É–Ω–¥ = 5 –º–∏–Ω—É—Ç)
        max_cache_items: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 18)
    
    Usage:
        @redis_cached_limited(prefix="anime_paginated", ttl=300, max_cache_items=18)
        async def pagination_get_anime(paginator_data: PaginatorData, ...):
            ...
    """
    def decorator(func: Callable) -> Callable:
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            # –ü–æ–ª—É—á–∞–µ–º –∫–ª–∏–µ–Ω—Ç Redis
            redis_client = await get_redis_client()
            
            # –ï—Å–ª–∏ Redis –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
            if not redis_client:
                return await func(*args, **kwargs)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º offset –∏ limit –∏–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤
            offset = 0
            limit = None
            
            # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π —Ç–∏–ø–∞ get_anime_sorted_by_score(limit, offset, ...)
            # –≠—Ç–æ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å–¥–µ–ª–∞–Ω–æ –¥–æ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ–±—ä–µ–∫—Ç–æ–≤, —Ç–∞–∫ –∫–∞–∫ int –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–µ—Ä–µ–¥–∞–Ω –ø–µ—Ä–≤—ã–º
            if len(args) > 0:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è—é—Ç—Å—è –ª–∏ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ limit –∏ offset
                if isinstance(args[0], int) and not hasattr(args[0], '__dict__'):
                    if len(args) > 1 and isinstance(args[1], int) and not hasattr(args[1], '__dict__'):
                        # –í–µ—Ä–æ—è—Ç–Ω–æ, —ç—Ç–æ limit –∏ offset
                        limit = args[0]
                        offset = args[1]
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ –≤ –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω—ã—Ö –∞—Ä–≥—É–º–µ–Ω—Ç–∞—Ö, –∏—â–µ–º –æ–±—ä–µ–∫—Ç PaginatorData –≤ args
            if limit is None:
                for arg in args:
                    if hasattr(arg, 'offset') and hasattr(arg, 'limit'):
                        # –≠—Ç–æ –æ–±—ä–µ–∫—Ç PaginatorData –∏–ª–∏ –ø–æ–¥–æ–±–Ω—ã–π
                        offset = getattr(arg, 'offset', 0)
                        limit = getattr(arg, 'limit', None)
                        break
            
            # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ –Ω–∞—à–ª–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º kwargs (–¥–ª—è —Ñ—É–Ω–∫—Ü–∏–π —Å –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏)
            if limit is None:
                if 'offset' in kwargs:
                    offset = kwargs['offset']
                if 'limit' in kwargs:
                    limit = kwargs.get('limit')
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ç–æ–ª—å–∫–æ –¥–ª—è offset=0 –∏ limit <= max_cache_items
            should_cache = offset == 0 and (limit is None or limit <= max_cache_items)
            
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∏ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤ —Ñ—É–Ω–∫—Ü–∏–∏
            # –î–ª—è —Å–µ—Å—Å–∏–π –∏ –¥—Ä—É–≥–∏—Ö –Ω–µ—Å–µ—Ä–∏–∞–ª–∏–∑—É–µ–º—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö id –∏–ª–∏ —Å—Ç—Ä–æ–∫–æ–≤–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ
            cache_key_parts = [prefix]
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∞—Ä–≥—É–º–µ–Ω—Ç—ã –≤ –∫–ª—é—á –∫—ç—à–∞
            for arg in args:
                # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º AsyncSession - —Å–µ—Å—Å–∏—è –Ω–µ –≤–ª–∏—è–µ—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∫—ç—à–∏—Ä—É–µ–º—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π
                if isinstance(arg, AsyncSession):
                    continue
                elif hasattr(arg, 'id'):
                    cache_key_parts.append(str(arg.id))
                elif isinstance(arg, (int, str, float, bool)):
                    cache_key_parts.append(str(arg))
                elif hasattr(arg, '__dict__'):
                    # –î–ª—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –∞—Ç—Ä–∏–±—É—Ç–∞–º–∏ —Å–æ–∑–¥–∞–µ–º —Ö—ç—à
                    arg_str = json.dumps(vars(arg), default=str, sort_keys=True)
                    arg_hash = hashlib.md5(arg_str.encode()).hexdigest()[:8]
                    cache_key_parts.append(arg_hash)
            
            # –î–æ–±–∞–≤–ª—è–µ–º kwargs (–∏—Å–∫–ª—é—á–∞—è —Å–µ—Å—Å–∏–∏)
            if kwargs:
                # –§–∏–ª—å—Ç—Ä—É–µ–º kwargs, –∏—Å–∫–ª—é—á–∞—è AsyncSession
                filtered_kwargs = {
                    k: v for k, v in kwargs.items() 
                    if not isinstance(v, AsyncSession)
                }
                if filtered_kwargs:
                    kwargs_str = json.dumps(filtered_kwargs, default=str, sort_keys=True)
                    kwargs_hash = hashlib.md5(kwargs_str.encode()).hexdigest()[:8]
                    cache_key_parts.append(kwargs_hash)
            
            cache_key = ":".join(cache_key_parts)
            
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ–ª–∂–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å
                if should_cache:
                    cached_data = await redis_client.get(cache_key)
                    if cached_data is not None:
                        try:
                            cached_result = json.loads(cached_data)
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –¥–∞–Ω–Ω—ã–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã (–Ω–µ —Å—Ç—Ä–æ–∫–∏ —Å –æ–±—ä–µ–∫—Ç–∞–º–∏)
                            is_valid = True
                            if isinstance(cached_result, list):
                                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞
                                for item in cached_result:
                                    if isinstance(item, str) and ('object at 0x' in item or 'AnimeModel' in item or 'Model' in item):
                                        is_valid = False
                                        break
                                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Å–ª–æ–≤–∞—Ä—å (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç) –∏–ª–∏ –æ–±—ä–µ–∫—Ç SQLAlchemy
                                    if not isinstance(item, dict) and not hasattr(item, '__table__'):
                                        if isinstance(item, str):
                                            is_valid = False
                                            break
                            elif isinstance(cached_result, str):
                                # –ï—Å–ª–∏ —ç—Ç–æ —Å—Ç—Ä–æ–∫–∞ —Å –æ–±—ä–µ–∫—Ç–æ–º - –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
                                if 'object at 0x' in cached_result or 'AnimeModel' in cached_result:
                                    is_valid = False
                            
                            if not is_valid:
                                logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à–µ (—Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç), –æ—á–∏—â–∞–µ–º –∫–ª—é—á: {cache_key}")
                                await redis_client.delete(cache_key)
                                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º)
                            else:
                                remaining_ttl = await redis_client.ttl(cache_key)
                                # –§–æ—Ä–º–∏—Ä—É–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                                params_info = f"offset={offset}, limit={limit}" if limit is not None else f"offset={offset}"
                                logger.debug(f"üéØ Cache HIT: {func.__name__} (key: {cache_key}, {params_info}, TTL remaining: {remaining_ttl}s)")
                                # –ï—Å–ª–∏ –∑–∞–ø—Ä–æ—à–µ–Ω–æ –º–µ–Ω—å—à–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤, —á–µ–º –≤ –∫—ç—à–µ, –æ–±—Ä–µ–∑–∞–µ–º
                                if isinstance(cached_result, list) and limit is not None and limit < len(cached_result):
                                    return cached_result[:limit]
                                return cached_result
                        except json.JSONDecodeError as e:
                            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∫—ç—à–∞ –¥–ª—è {func.__name__}: {e}, –æ—á–∏—â–∞–µ–º –∫–ª—é—á: {cache_key}")
                            await redis_client.delete(cache_key)
                
                # –ö—ç—à –ø—Ä–æ–º–∞—Ö –∏–ª–∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å - –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
                if not should_cache:
                    params_info = f"offset={offset}, limit={limit}" if limit is not None else f"offset={offset}"
                    logger.debug(f"‚è≠Ô∏è Skip cache: {func.__name__} ({params_info}, max_cache={max_cache_items})")
                else:
                    params_info = f"offset={offset}, limit={limit}" if limit is not None else f"offset={offset}"
                    logger.info(f"üí® Cache MISS: {func.__name__} (key: {cache_key}, {params_info}) - –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –∑–∞–ø—Ä–æ—Å –∫ –ë–î")
                
                result = await func(*args, **kwargs)
                
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –¥–æ–ª–∂–Ω—ã –∫—ç—à–∏—Ä–æ–≤–∞—Ç—å –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç - —Å–ø–∏—Å–æ–∫
                if should_cache and isinstance(result, list):
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ max_cache_items —ç–ª–µ–º–µ–Ω—Ç–æ–≤
                    cache_data = result[:max_cache_items] if len(result) > max_cache_items else result
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –∫—ç—à
                    try:
                        # –°–µ—Ä–∏–∞–ª–∏–∑—É–µ–º SQLAlchemy –æ–±—ä–µ–∫—Ç—ã –≤ —Å–ª–æ–≤–∞—Ä–∏ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
                        serializable_cache_data = serialize_for_cache(cache_data)
                        serialized_result = json.dumps(serializable_cache_data, default=str)
                        result_size = len(serialized_result.encode('utf-8'))
                        await redis_client.setex(cache_key, ttl, serialized_result)
                        logger.info(f"üíæ Cached {func.__name__} (TTL: {ttl}s, key: {cache_key}, cached_items: {len(cache_data)}, total_items: {len(result)}, size: {result_size} bytes)")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è Failed to cache result for {func.__name__}: {e}")
                
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–Ω–µ –æ–±—Ä–µ–∑–∞–Ω–Ω—ã–π)
                return result
                
            except Exception as e:
                logger.error(f"Redis cache error for {func.__name__}: {e}")
                # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é –±–µ–∑ –∫—ç—à–∞
                return await func(*args, **kwargs)
        
        return wrapper
    return decorator
